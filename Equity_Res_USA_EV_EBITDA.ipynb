{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "# 1. FOLDER SETUP (The Fix for GitHub Portability)\n",
    "DATA_FOLDER = \"YfinanceDataDump\"  # Relative path (creates folder in project root)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"\n",
    "\n",
    "# 2. FILE PATHS (Everything saves inside the folder now)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\")\n",
    "DEEPVAL_CSV = os.path.join(DATA_FOLDER, \"Deep_Value_Gems.csv\")\n",
    "# 3. UNIVERSE FILTERS\n",
    "MIN_PRICE = 2.00               \n",
    "MIN_VOLUME = 1_000_000       \n",
    "MIN_CAP = 300_000_000        # $300M\n",
    "MIN_CURRENT_RATIO = 1.2\n",
    "MAX_PE_RATIO = 100.0         \n",
    "\n",
    "# 4. SAFETY THRESHOLDS \n",
    "MIN_INTEREST_COVERAGE = 1.5\n",
    "MIN_ROIC = 0.05              # 5%\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # 5%\n",
    "\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "CACHE_EXPIRY_DAYS = 30 \n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculates Z-Score using yfinance DataFrames.\n",
    "    Formula: 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper to safely get value from Series\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Map yfinance row names\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        if total_assets == 0 or total_liab == 0: return 0\n",
    "\n",
    "        # A: Working Capital / Total Assets\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings / Total Assets\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT / Total Assets\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Value of Equity / Total Liabilities\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Sales / Total Assets\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: FETCH COMBINED UNIVERSE (USA + CAD)\n",
    "# ==========================================\n",
    "def get_combined_universe():\n",
    "    print(\"--- STEP 1: Fetching North American Universe ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # 1. USA\n",
    "    try:\n",
    "        url_us = \"https://www.nasdaqtrader.com/dynamic/symdir/nasdaqtraded.txt\"\n",
    "        s = requests.get(url_us).content\n",
    "        df_us = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='|')\n",
    "        df_us = df_us[(df_us['Test Issue'] == 'N') & (df_us['ETF'] == 'N')]\n",
    "        us_list = [x.replace('$', '-') for x in df_us['Symbol'].astype(str) if len(x) < 5]\n",
    "        tickers.extend(us_list)\n",
    "        print(f\"   -> Found {len(us_list)} US stocks.\")\n",
    "    except:\n",
    "        print(\"   -> Error fetching USA list.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2: LIGHTWEIGHT SIEVE (YahooQuery)\n",
    "# ==========================================\n",
    "def get_initial_survivors(tickers):\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    chunk_size = 500 \n",
    "    survivors = []\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 2 == 0: print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_modules = yq.get_modules('summaryProfile summaryDetail financialData price defaultKeyStatistics')\n",
    "            \n",
    "            for symbol, data in df_modules.items():\n",
    "                if isinstance(data, str): continue \n",
    "                try:\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: price = 0\n",
    "                    \n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                         vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: cap = 0\n",
    "                    \n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)\n",
    "                    if curr_ratio is None: curr_ratio = 0\n",
    "                    if op_margins is None: op_margins = 0\n",
    "\n",
    "                    # --- P/E RATIO CHECK ---\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: continue\n",
    "\n",
    "                    # FILTERS\n",
    "                    if price < MIN_PRICE: continue\n",
    "                    if cap < MIN_CAP: continue\n",
    "                    if vol < MIN_VOLUME: continue \n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): continue\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: continue\n",
    "                    if op_margins <= 0: continue \n",
    "                    \n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)\n",
    "                    })\n",
    "                except: continue\n",
    "        except: continue\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 3: DEEP DIVE (yfinance + Cache)\n",
    "# ==========================================\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    cache = load_cache()\n",
    "    current_time = time.time()\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 20 == 0: print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        # --- CRITICAL FIX: Anti-Throttle Sleep ---\n",
    "        #time.sleep(0.75)  # Sleep to avoid hitting Yahoo too fast change back to 1 second if throttling occurs\n",
    "        # -----------------------------------------\n",
    "        \n",
    "        # Helper: Logic to assign Tier based on Average Margin & Safety\n",
    "        def determine_tier_history(metrics, is_fortress_margin, is_pos_margin):\n",
    "            # 1. Safety Checks (Must pass these regardless of margins)\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: return \"Risky\"\n",
    "            \n",
    "            # 2. Historical Margin Checks (Using the 4-Year Average)\n",
    "            if is_fortress_margin: \n",
    "                return \"Fortress\"  # Avg Margin > 5%\n",
    "            elif is_pos_margin:\n",
    "                return \"Strong\"    # Avg Margin > 0%\n",
    "            \n",
    "            return \"Risky\"         # Avg Margin was negative\n",
    "\n",
    "        # 1. CHECK CACHE\n",
    "        cached_data = cache.get(ticker)\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "            if cached_data.get('roic') == -999: continue \n",
    "            # If using cache, we might miss the 'avg_margin' recalculation unless we force update.\n",
    "            # ideally we proceed to fetch if we suspect cache is old logic, but for now we trust cache.\n",
    "            # To force new logic, clear your cache file (delete financial_cache.json).\n",
    "            pass \n",
    "\n",
    "        # 2. FETCH NEW DATA\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials\n",
    "            bs = stock.balance_sheet\n",
    "            \n",
    "            # Check if Yahoo actually gave us data\n",
    "            if fin.empty or bs.empty:\n",
    "                # Don't cache this as a failure immediately; it might be a connection blip.\n",
    "                # But to keep logic simple, we skip.\n",
    "                print(f\"   ‚ö†Ô∏è No data for {ticker} (skipping)\")\n",
    "                continue\n",
    "            \n",
    "            # --- A. NEW LOGIC: 4-Year Average Margin Check ---\n",
    "            try:\n",
    "                # Get Operating Income (try 'Operating Income' first, then 'EBIT')\n",
    "                if 'Operating Income' in fin.index:\n",
    "                    op_income_history = fin.loc['Operating Income']\n",
    "                elif 'EBIT' in fin.index:\n",
    "                    op_income_history = fin.loc['EBIT']\n",
    "                else:\n",
    "                    op_income_history = pd.Series([0]) \n",
    "\n",
    "                # Get Revenue\n",
    "                revenue_history = fin.loc['Total Revenue']\n",
    "                \n",
    "                # Calculate Margins for every available year\n",
    "                # This automatically handles 1, 2, 3, or 4 years of data\n",
    "                yearly_margins = (op_income_history / revenue_history).dropna()\n",
    "                \n",
    "                if len(yearly_margins) > 0:\n",
    "                    avg_margin = yearly_margins.mean()\n",
    "                    \n",
    "                    # The Uniform Rule: Is the AVERAGE above the threshold?\n",
    "                    is_fortress_margin = avg_margin > FORTRESS_MARGIN_THRESHOLD\n",
    "                    is_positive_margin = avg_margin > 0\n",
    "                else:\n",
    "                    is_fortress_margin = False\n",
    "                    is_positive_margin = False\n",
    "\n",
    "            except Exception as e:\n",
    "                # Fail safe\n",
    "                is_fortress_margin = False\n",
    "                is_positive_margin = False\n",
    "            # ---------------------------------------------------\n",
    "\n",
    "            # --- B. Standard Calculations (Safety Checks) ---\n",
    "            def get_item(df, keys):\n",
    "                for k in keys:\n",
    "                    if k in df.index: return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            # Interest Coverage\n",
    "            int_exp = abs(int_exp)\n",
    "            if int_exp == 0: int_cov = 100\n",
    "            else: int_cov = ebit / int_exp\n",
    "            \n",
    "            # ROIC\n",
    "            invested_cap = total_assets - curr_liab\n",
    "            if invested_cap <= 0: roic = 0\n",
    "            else: roic = ebit / invested_cap\n",
    "            \n",
    "            # Z-Score\n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            # Cache the metrics\n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            # --- C. Determine Final Tier ---\n",
    "            tier = determine_tier_history(metrics, is_fortress_margin, is_positive_margin)\n",
    "\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'], \n",
    "                'Avg Margin (4Y)': round(avg_margin * 100, 2) if 'avg_margin' in locals() else 0,\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    save_cache(cache)\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching North American Universe ---\n",
      "   -> Found 6013 US stocks.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 6013 stocks ---\n",
      " -> Processing Batch 1/13...\n",
      " -> Processing Batch 3/13...\n",
      " -> Processing Batch 5/13...\n",
      " -> Processing Batch 7/13...\n",
      " -> Processing Batch 9/13...\n",
      " -> Processing Batch 11/13...\n",
      " -> Processing Batch 13/13...\n",
      "\n",
      "‚úÖ Step 2 Complete. 549 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 549 Survivors ---\n",
      " -> Analyzing 1/549: A...\n",
      " -> Analyzing 21/549: ALGN...\n",
      " -> Analyzing 41/549: AQN...\n",
      " -> Analyzing 61/549: AXL...\n",
      " -> Analyzing 81/549: BMBL...\n",
      " -> Analyzing 101/549: CDE...\n",
      " -> Analyzing 121/549: COP...\n",
      " -> Analyzing 141/549: CXM...\n",
      " -> Analyzing 161/549: DRS...\n",
      " -> Analyzing 181/549: ET...\n",
      " -> Analyzing 201/549: FND...\n",
      " -> Analyzing 221/549: GILD...\n",
      " -> Analyzing 241/549: HAL...\n",
      " -> Analyzing 261/549: HUM...\n",
      " -> Analyzing 281/549: ITGR...\n",
      " -> Analyzing 301/549: LFST...\n",
      " -> Analyzing 321/549: MGY...\n",
      " -> Analyzing 341/549: NEM...\n",
      " -> Analyzing 361/549: OKTA...\n",
      " -> Analyzing 381/549: PGY...\n",
      " -> Analyzing 401/549: QRVO...\n",
      " -> Analyzing 421/549: RVTY...\n",
      " -> Analyzing 441/549: SMCI...\n",
      " -> Analyzing 461/549: SU...\n",
      " -> Analyzing 481/549: TNGX...\n",
      " -> Analyzing 501/549: UGP...\n",
      " -> Analyzing 521/549: VSH...\n",
      " -> Analyzing 541/549: XYZ...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (323): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (30): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (192): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "    Ticker      Tier   Price    P/E                  Sector  Z-Score  ROIC %  Op Margin %  Avg Margin (4Y)  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "528    WPM  Fortress  117.52  53.42         Basic Materials   195.45    8.72        66.54            50.89       8.089  2269.82        53.43\n",
      "345   NVDA  Fortress  186.50  46.05              Technology    89.60   90.08        63.17            43.63       4.468   341.19      4540.72\n",
      "276   ISRG  Fortress  566.36  75.21              Healthcare    56.74   13.82        30.33            27.54       4.728   100.00       203.03\n",
      "405   RGLD  Fortress  222.29  30.49         Basic Materials    44.21   13.18        50.53            51.72       3.516    44.71        18.76\n",
      "35     APP  Fortress  673.82  79.37  Communication Services    30.88   39.37        76.80            15.80       3.250     5.95       227.92\n",
      "185   FAST  Fortress   40.13  37.86             Industrials    29.95   37.78        20.70            20.47       4.259   207.59        46.07\n",
      "154   DOCS  Fortress   44.28  35.42              Healthcare    29.69   20.77        38.55            34.85       7.786   100.00         8.34\n",
      "321   MNST  Fortress   76.67  43.56      Consumer Defensive    29.06   29.15        30.74            27.67       3.185   100.00        74.91\n",
      "119   CPRT  Fortress   39.15  24.02             Industrials    28.48   18.04        37.29            37.83       7.939      NaN        37.90\n",
      "410   RMBS  Fortress   91.89  43.76              Technology    27.97   15.97        35.43            19.68      11.609   142.27         9.89\n",
      "29    ANET  Fortress  131.03  49.82              Technology    27.18   26.03        42.38            36.70       3.254   100.00       165.00\n",
      "46     ASM  Fortress    6.21  44.36         Basic Materials    25.54   11.12        32.56             6.68       2.754    38.26         0.97\n",
      "467    TER  Fortress  193.56  70.39              Technology    22.83   19.87        18.89            24.67       1.759   170.80        30.79\n",
      "230   GOOG  Fortress  313.80  30.95  Communication Services    20.78   33.25        30.51            29.14       1.747   448.07      3788.14\n",
      "483   TSEM  Fortress  117.42  67.87              Technology    19.53    7.92        12.78            14.02       6.610    54.97        13.17\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n‚úÖ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                final_results = final_results.sort_values(by=['Tier', 'Z-Score'], ascending=[True, False])\n",
    "                \n",
    "                # 1. Standard Split\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # 3. Save Files (Updated to use Relative Paths from Cell 2)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error Saving Files: {e}\")\n",
    "                    print(\"Check if the file is open in Excel or if the folder exists.\")\n",
    "                \n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 323 Stocks (From Memory) ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/323: WPM...\n",
      " -> Analyst Scan 11/323: ANET...\n",
      " -> Analyst Scan 21/323: CDNS...\n",
      " -> Analyst Scan 31/323: GMAB...\n",
      " -> Analyst Scan 41/323: SGHC...\n",
      " -> Analyst Scan 51/323: REGN...\n",
      " -> Analyst Scan 61/323: ELF...\n",
      " -> Analyst Scan 71/323: GFI...\n",
      " -> Analyst Scan 81/323: DHI...\n",
      " -> Analyst Scan 91/323: DLO...\n",
      " -> Analyst Scan 101/323: ETN...\n",
      " -> Analyst Scan 111/323: RES...\n",
      " -> Analyst Scan 121/323: CAT...\n",
      " -> Analyst Scan 131/323: CGAU...\n",
      " -> Analyst Scan 141/323: TMO...\n",
      " -> Analyst Scan 151/323: MAS...\n",
      " -> Analyst Scan 161/323: FSM...\n",
      " -> Analyst Scan 171/323: PPC...\n",
      " -> Analyst Scan 181/323: HRL...\n",
      " -> Analyst Scan 191/323: NXPI...\n",
      " -> Analyst Scan 201/323: UPS...\n",
      " -> Analyst Scan 211/323: HAFN...\n",
      " -> Analyst Scan 221/323: LEVI...\n",
      " -> Analyst Scan 231/323: TSM...\n",
      " -> Analyst Scan 241/323: M...\n",
      " -> Analyst Scan 251/323: LW...\n",
      " -> Analyst Scan 261/323: NWSA...\n",
      " -> Analyst Scan 271/323: NOK...\n",
      " -> Analyst Scan 281/323: DEO...\n",
      " -> Analyst Scan 291/323: DOW...\n",
      " -> Analyst Scan 301/323: BIDU...\n",
      " -> Analyst Scan 311/323: SBLK...\n",
      " -> Analyst Scan 321/323: MTCH...\n",
      "\n",
      "‚úÖ Analyst Scan Complete!\n",
      "Found 120 stocks with Buy Ratings (Score < 2.0)\n",
      "Saved to 'Analyst_Fortress_Picks.csv'\n",
      "    Ticker   Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "110    CXW   19.11         1.00000     56.33     29.875000  Fortress\n",
      "103    TME   17.53         1.40625     53.39     26.889978  Fortress\n",
      "27     ELF   76.04         1.62500     51.80    115.428570  Fortress\n",
      "67    GNRC  136.37         1.80952     51.45    206.529400  Fortress\n",
      "79    BIRK   40.90         1.50000     49.44     61.119843  Fortress\n",
      "20    SGHC   11.95         1.25000     47.49     17.625000  Fortress\n",
      "75    SMPL   20.08         2.00000     47.41     29.600000  Fortress\n",
      "108   GPRK    7.41         1.85714     47.10     10.900000  Fortress\n",
      "36    BRBR   26.73         1.81250     42.16     38.000000  Fortress\n",
      "99    NWSA   26.12         1.75000     40.45     36.685710  Fortress\n",
      "38      DT   43.34         1.58333     40.24     60.781250  Fortress\n",
      "92     JBS   14.42         1.33333     39.37     20.096790  Fortress\n",
      "96     LKQ   30.20         1.77778     36.38     41.187500  Fortress\n",
      "0     NVDA  186.50         1.32812     35.67    253.018250  Fortress\n",
      "106   BABA  146.58         1.44186     35.47    198.570190  Fortress\n",
      "22    CGNX   35.98         1.90476     35.21     48.650000  Fortress\n",
      "109    FRO   21.82         1.25000     34.62     29.375000  Fortress\n",
      "15    NFLX   93.76         1.95349     34.59    126.191840  Fortress\n",
      "46     BSX   95.35         1.32353     32.00    125.857810  Fortress\n",
      "10    AVGO  346.10         1.27083     31.99    456.802000  Fortress\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the function (if you haven't already in a previous cell)\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks (From Memory) ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 10 == 0: print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Must be better than 2.0 (Lower is better)\n",
    "            if rec_mean is None or rec_mean > 2.0: continue\n",
    "            \n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Merge with existing data\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2) # Polite delay\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE IT (Run this part!)\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by best Analyst Rating (Lower is better) or Upside\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        # Display Results\n",
    "        print(\"\\n‚úÖ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(\"Saved to 'Analyst_Fortress_Picks.csv'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 545 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "‚ùå No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "# ==========================================\n",
    "# BUFFETT \"BELOW NAV\" SCAN\n",
    "# ==========================================\n",
    "def get_buffett_value_picks(df_input):\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Use YahooQuery for speed (Key Stats are summary data, no throttling risk here)\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # We need defaultKeyStatistics (P/B) and financialData (ROE, Debt)\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        # Skip if None, > 1.0, or negative (insolvent)\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: continue\n",
    "\n",
    "                        # 2. Positive ROE (No Zombies)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: continue\n",
    "\n",
    "                        # 3. Reasonable Debt (Safety)\n",
    "                        # Buffett hates high leverage on weak companies\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: continue \n",
    "\n",
    "                        # Get base data from input_df\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "\n",
    "                        # Add new Value Metrics\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: continue\n",
    "        except: continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION BLOCK\n",
    "# ==========================================\n",
    "# Ensure we have the 'final_results' from the Main Filter\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    \n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        # Sort by P/B Ratio (Cheapest first)\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        \n",
    "        # Save results\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks (Trading < Book Value)\")\n",
    "        print(\"Saved to: 'Buffett_Value_Picks.csv'\")\n",
    "        \n",
    "        # Display\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\")\n",
    "else:\n",
    "    print(\"‚ùå 'final_results' variable not found. Please run the Main Filter first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c744c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 323 stocks for Insider Buying & Price...\n",
      "‚úÖ Created 'Fortress_insiders' with 15 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "93432903-115a-4c06-875b-b74d76dcd5b4",
       "rows": [
        [
         "0",
         "KEYS",
         "203.19",
         "15",
         "1368070.0"
        ],
        [
         "1",
         "SHLS",
         "8.5",
         "3",
         "8335.0"
        ],
        [
         "2",
         "CGAU",
         "14.37",
         "91",
         "5359745.0"
        ],
        [
         "3",
         "DKS",
         "197.97",
         "1",
         "2000.0"
        ],
        [
         "4",
         "FSM",
         "9.81",
         "4",
         "916900.0"
        ],
        [
         "5",
         "OPCH",
         "31.86",
         "8",
         "18954.0"
        ],
        [
         "6",
         "MPC",
         "162.63",
         "3",
         "413316.0"
        ],
        [
         "7",
         "UPS",
         "99.19",
         "5",
         "16257.0"
        ],
        [
         "8",
         "TXT",
         "87.17",
         "17",
         "1259880.0"
        ],
        [
         "9",
         "CVE",
         "16.92",
         "73",
         "53965480.0"
        ],
        [
         "10",
         "ESI",
         "24.99",
         "61",
         "11612551.0"
        ],
        [
         "11",
         "PFE",
         "24.9",
         "2",
         "12803.0"
        ],
        [
         "12",
         "MOMO",
         "6.55",
         "11",
         "703246.0"
        ],
        [
         "13",
         "SLGN",
         "40.37",
         "1",
         "1120.0"
        ],
        [
         "14",
         "SEE",
         "41.43",
         "4",
         "39639.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KEYS</td>\n",
       "      <td>203.19</td>\n",
       "      <td>15</td>\n",
       "      <td>1368070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>8.50</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGAU</td>\n",
       "      <td>14.37</td>\n",
       "      <td>91</td>\n",
       "      <td>5359745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DKS</td>\n",
       "      <td>197.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FSM</td>\n",
       "      <td>9.81</td>\n",
       "      <td>4</td>\n",
       "      <td>916900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OPCH</td>\n",
       "      <td>31.86</td>\n",
       "      <td>8</td>\n",
       "      <td>18954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MPC</td>\n",
       "      <td>162.63</td>\n",
       "      <td>3</td>\n",
       "      <td>413316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UPS</td>\n",
       "      <td>99.19</td>\n",
       "      <td>5</td>\n",
       "      <td>16257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXT</td>\n",
       "      <td>87.17</td>\n",
       "      <td>17</td>\n",
       "      <td>1259880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CVE</td>\n",
       "      <td>16.92</td>\n",
       "      <td>73</td>\n",
       "      <td>53965480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ESI</td>\n",
       "      <td>24.99</td>\n",
       "      <td>61</td>\n",
       "      <td>11612551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PFE</td>\n",
       "      <td>24.90</td>\n",
       "      <td>2</td>\n",
       "      <td>12803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MOMO</td>\n",
       "      <td>6.55</td>\n",
       "      <td>11</td>\n",
       "      <td>703246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SLGN</td>\n",
       "      <td>40.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SEE</td>\n",
       "      <td>41.43</td>\n",
       "      <td>4</td>\n",
       "      <td>39639.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0    KEYS         203.19                  15          1368070.0\n",
       "1    SHLS           8.50                   3             8335.0\n",
       "2    CGAU          14.37                  91          5359745.0\n",
       "3     DKS         197.97                   1             2000.0\n",
       "4     FSM           9.81                   4           916900.0\n",
       "5    OPCH          31.86                   8            18954.0\n",
       "6     MPC         162.63                   3           413316.0\n",
       "7     UPS          99.19                   5            16257.0\n",
       "8     TXT          87.17                  17          1259880.0\n",
       "9     CVE          16.92                  73         53965480.0\n",
       "10    ESI          24.99                  61         11612551.0\n",
       "11    PFE          24.90                   2            12803.0\n",
       "12   MOMO           6.55                  11           703246.0\n",
       "13   SLGN          40.37                   1             1120.0\n",
       "14    SEE          41.43                   4            39639.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "\n",
    "# Ignore these specific FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ==========================================\n",
    "# INSIDER FILTER FUNCTION (With Price)\n",
    "# ==========================================\n",
    "def filter_for_insider_buying(tickers):\n",
    "    print(f\"üïµÔ∏è Scanning {len(tickers)} stocks for Insider Buying & Price...\")\n",
    "    insider_picks = []\n",
    "    \n",
    "    # Chunk to prevent timeouts\n",
    "    chunk_size = 20\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            # Initialize Ticker object for the chunk\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            \n",
    "            # 1. Fetch Insider Transactions\n",
    "            df_insiders = yq.insider_transactions\n",
    "            \n",
    "            # 2. Fetch Price Data (New Step)\n",
    "            # This returns a dictionary: {'TICKER': {'regularMarketPrice': 10.50, ...}}\n",
    "            price_data = yq.price\n",
    "            \n",
    "            # Validation: Ensure we have data to work with\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, 'reset_index'): \n",
    "                continue\n",
    "            \n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders['symbol'].values:\n",
    "                    continue\n",
    "                \n",
    "                # --- INSIDER LOGIC ---\n",
    "                stock_tx = df_insiders[df_insiders['symbol'] == symbol].copy()\n",
    "                \n",
    "                buys = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Purchase\", case=False, na=False)]\n",
    "                sells = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Sale\", case=False, na=False)]\n",
    "                \n",
    "                buy_vol = buys['shares'].sum() if not buys.empty else 0\n",
    "                sell_vol = sells['shares'].sum() if not sells.empty else 0\n",
    "                \n",
    "                # --- PRICE LOGIC ---\n",
    "                current_price = None\n",
    "                try:\n",
    "                    # Safely attempt to grab the price from the dictionary\n",
    "                    if isinstance(price_data, dict) and symbol in price_data:\n",
    "                        current_price = price_data[symbol].get('regularMarketPrice', None)\n",
    "                except Exception:\n",
    "                    current_price = None\n",
    "\n",
    "                # Only keep if Net Buying is Positive\n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Current_Price': current_price, # <--- New Column\n",
    "                        'Insider_Buys_Count': len(buys),\n",
    "                        'Net_Shares_Bought': buy_vol - sell_vol\n",
    "                    })\n",
    "                        \n",
    "        except Exception as e:\n",
    "            # print(f\"Error on chunk: {e}\") # Uncomment for debugging\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE 'Fortress_insiders' DATAFRAME\n",
    "# ==========================================\n",
    "\n",
    "# Use fortress_df if it exists, otherwise use the top 20 backup list\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'fortress_df' not found or empty.\")\n",
    "\n",
    "# Run the filter\n",
    "Fortress_insiders = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# Display so Data Wrangler picks it up\n",
    "print(f\"‚úÖ Created 'Fortress_insiders' with {len(Fortress_insiders)} rows.\")\n",
    "display(Fortress_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 323 stocks for Insider Buying & Price...\n",
      "‚ö†Ô∏è No Analyst ratings found for these tickers.\n",
      "\n",
      "üöÄ Final List: 8 stocks (Fortress + Insider Buying + Analyst Buy Rating)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9a90c388-79b1-41d9-afb5-00cb104a1882",
       "rows": [
        [
         "0",
         "SHLS",
         "8.5",
         "3",
         "8335"
        ],
        [
         "1",
         "CGAU",
         "14.37",
         "91",
         "5359745"
        ],
        [
         "2",
         "DKS",
         "197.97",
         "1",
         "2000"
        ],
        [
         "3",
         "TOL",
         "135.22",
         "10",
         "3529615"
        ],
        [
         "4",
         "UPS",
         "99.19",
         "5",
         "16257"
        ],
        [
         "5",
         "TXT",
         "87.17",
         "17",
         "1259880"
        ],
        [
         "6",
         "CVE",
         "16.92",
         "73",
         "53965480"
        ],
        [
         "7",
         "ESI",
         "24.99",
         "61",
         "11612551"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>8.50</td>\n",
       "      <td>3</td>\n",
       "      <td>8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGAU</td>\n",
       "      <td>14.37</td>\n",
       "      <td>91</td>\n",
       "      <td>5359745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DKS</td>\n",
       "      <td>197.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOL</td>\n",
       "      <td>135.22</td>\n",
       "      <td>10</td>\n",
       "      <td>3529615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPS</td>\n",
       "      <td>99.19</td>\n",
       "      <td>5</td>\n",
       "      <td>16257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXT</td>\n",
       "      <td>87.17</td>\n",
       "      <td>17</td>\n",
       "      <td>1259880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CVE</td>\n",
       "      <td>16.92</td>\n",
       "      <td>73</td>\n",
       "      <td>53965480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESI</td>\n",
       "      <td>24.99</td>\n",
       "      <td>61</td>\n",
       "      <td>11612551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0   SHLS           8.50                   3               8335\n",
       "1   CGAU          14.37                  91            5359745\n",
       "2    DKS         197.97                   1               2000\n",
       "3    TOL         135.22                  10            3529615\n",
       "4    UPS          99.19                   5              16257\n",
       "5    TXT          87.17                  17            1259880\n",
       "6    CVE          16.92                  73           53965480\n",
       "7    ESI          24.99                  61           11612551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "        \n",
    "    tickers = df_insiders['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders # Return original if no data found\n",
    "            \n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list just in case\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(insider_winners, max_score=2.5)\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\")\n",
    "    display(Fortress_insiders_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d999738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Analyzing EV/EBITDA for 323 Fortress stocks...\n",
      "‚ö†Ô∏è Could not retrieve EV/EBITDA data (even with manual fallback).\n",
      "No stocks found trading below their sector average.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# BURRY \"RELATIVE VALUE\" FILTER (EV/EBITDA)\n",
    "# ==========================================\n",
    "def filter_burry_ev_ebitda(df_input):\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"‚ùå Input DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"üìâ Analyzing EV/EBITDA for {len(df_input)} Fortress stocks...\")\n",
    "    \n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    \n",
    "    # 1. BATCH FETCH DATA (YahooQuery for Speed)\n",
    "    # We fetch multiple modules now to ensure we have ingredients for manual calc\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # Fetch key stats (pre-calced), financial data (debt/cash), and summary (market cap)\n",
    "        data = yq.get_modules('defaultKeyStatistics financialData summaryDetail')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ev_data = []\n",
    "    \n",
    "    # 2. PARSE DATA\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Safe extraction of modules\n",
    "            ticker_data = data.get(ticker, {})\n",
    "            if isinstance(ticker_data, str): continue # Handle API errors\n",
    "            \n",
    "            stats = ticker_data.get('defaultKeyStatistics', {})\n",
    "            fin_data = ticker_data.get('financialData', {})\n",
    "            summary = ticker_data.get('summaryDetail', {})\n",
    "\n",
    "            # --- PLAN A: Pre-calculated Metric ---\n",
    "            ev_ebitda = stats.get('enterpriseToEbitda')\n",
    "            \n",
    "            # --- PLAN B: Manual Calculation (The Fallback) ---\n",
    "            if ev_ebitda is None:\n",
    "                try:\n",
    "                    # We need all 4 components to calculate it manually\n",
    "                    market_cap = summary.get('marketCap')\n",
    "                    total_debt = fin_data.get('totalDebt')\n",
    "                    total_cash = fin_data.get('totalCash')\n",
    "                    ebitda = fin_data.get('ebitda')\n",
    "                    \n",
    "                    if all(v is not None for v in [market_cap, total_debt, total_cash, ebitda]):\n",
    "                        if ebitda != 0:\n",
    "                            # Formula: EV = Market Cap + Debt - Cash\n",
    "                            enterprise_value = market_cap + total_debt - total_cash\n",
    "                            ev_ebitda = enterprise_value / ebitda\n",
    "                            # print(f\"   -> Manual Calc success for {ticker}: {round(ev_ebitda, 2)}\")\n",
    "                except Exception:\n",
    "                    pass # If manual calc fails, we just skip\n",
    "\n",
    "            # Filter: We only want profitable EBITDA for valuation (exclude negatives/None)\n",
    "            if ev_ebitda is not None and ev_ebitda > 0:\n",
    "                ev_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'EV/EBITDA': round(ev_ebitda, 2)\n",
    "                })\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    df_vals = pd.DataFrame(ev_data)\n",
    "    \n",
    "    if df_vals.empty:\n",
    "        print(\"‚ö†Ô∏è Could not retrieve EV/EBITDA data (even with manual fallback).\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 3. MERGE WITH SECTOR DATA\n",
    "    # We merge back with original DF to get the 'Sector' column\n",
    "    merged_df = pd.merge(df_input, df_vals, on='Ticker', how='inner')\n",
    "    \n",
    "    # 4. CALCULATE SECTOR AVERAGES\n",
    "    print(\"\\n--- üìä SECTOR AVERAGES (EV/EBITDA) ---\")\n",
    "    sector_stats = merged_df.groupby('Sector')['EV/EBITDA'].mean().reset_index()\n",
    "    sector_stats.rename(columns={'EV/EBITDA': 'Sector_Avg_EV_EBITDA'}, inplace=True)\n",
    "    sector_stats['Sector_Avg_EV_EBITDA'] = sector_stats['Sector_Avg_EV_EBITDA'].round(2)\n",
    "    \n",
    "    # Print the Benchmark Table\n",
    "    print(sector_stats.to_string(index=False))\n",
    "    \n",
    "    # 5. FILTER: STOCK < SECTOR AVERAGE\n",
    "    final_df = pd.merge(merged_df, sector_stats, on='Sector', how='left')\n",
    "    \n",
    "    # The Burry Filter: Value must be lower than the peer average\n",
    "    burry_picks = final_df[final_df['EV/EBITDA'] < final_df['Sector_Avg_EV_EBITDA']].copy()\n",
    "    \n",
    "    # Calculate \"Discount\" metric for sorting\n",
    "    burry_picks['Discount_%'] = round((1 - (burry_picks['EV/EBITDA'] / burry_picks['Sector_Avg_EV_EBITDA'])) * 100, 2)\n",
    "    \n",
    "    # Sort by the biggest discount relative to sector\n",
    "    burry_picks = burry_picks.sort_values(by='Discount_%', ascending=False)\n",
    "    \n",
    "    return burry_picks\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "# Ensure we use the fortress_df from previous steps\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "    \n",
    "    if not Fortress_Burry_EV_EBITDA.empty:\n",
    "        print(f\"\\n‚úÖ Found {len(Fortress_Burry_EV_EBITDA)} Undervalued Stocks (Cheaper than Sector Avg).\")\n",
    "        print(\"Created variable: 'Fortress_Burry_EV_EBITDA'\")\n",
    "        \n",
    "        # Display for Data Wrangler\n",
    "        display(Fortress_Burry_EV_EBITDA[['Ticker', 'Sector', 'Price', 'EV/EBITDA', 'Sector_Avg_EV_EBITDA', 'Discount_%', 'Tier']])\n",
    "    else:\n",
    "        print(\"No stocks found trading below their sector average.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'fortress_df' variable not found. Please run Step 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efa7b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Analyzing EV/EBITDA for 323 Fortress stocks...\n",
      "‚ö†Ô∏è Could not retrieve EV/EBITDA data (even with manual fallback).\n",
      "No stocks passed all filters.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. ANALYST FILTER FUNCTION FOR Burry EV/EBITA\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if Fortress_Burry_EV_EBITDA.empty:\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "        \n",
    "    tickers = Fortress_Burry_EV_EBITDA['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return Fortress_Burry_EV_EBITDA # Return original if no data found\n",
    "            \n",
    "        # Merge with the Fortress DataFrame\n",
    "        merged = pd.merge(Fortress_Burry_EV_EBITDA, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'Fortress_Burry_EV_EBITDA' in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    target_tickers = Fortress_Burry_EV_EBITDA['Ticker'].tolist()\n",
    "\n",
    "\n",
    "# B. Run Insider Filter\n",
    "Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not Fortress_Burry_EV_EBITDA.empty:\n",
    "    Fortress_Burry_Analyst_buy = filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5)\n",
    "else:\n",
    "    Fortress_Burry_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_Burry_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_Burry_Analyst_buy)} stocks (Fortress + Burry + Analyst Buy Rating)\")\n",
    "    display(Fortress_Burry_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ec288b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cannot combine. One of the filters returned 0 results.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üíé THE \"DEEP VALUE\" INTERSECTION (Buffett + Burry)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Ensure we have the Buffett Data\n",
    "# (If you haven't run the Buffett scanner in this notebook yet, this runs it now)\n",
    "if 'Buffett_Value_DF' not in locals():\n",
    "    print(\"üîÑ Buffett Data not found. Running scan now...\")\n",
    "    if 'get_buffett_value_picks' in globals() and 'final_results' in locals():\n",
    "        Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Missing 'final_results' or 'get_buffett_value_picks' function.\")\n",
    "        Buffett_Value_DF = pd.DataFrame()\n",
    "\n",
    "# 2. Ensure we have the Burry Data\n",
    "if 'Fortress_Burry_EV_EBITDA' not in locals():\n",
    "    print(\"‚ö†Ô∏è Please run the Burry EV/EBITDA filter cell first.\")\n",
    "    Fortress_Burry_EV_EBITDA = pd.DataFrame()\n",
    "\n",
    "# 3. THE MERGE (Finding the Overlap)\n",
    "if not Buffett_Value_DF.empty and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    \n",
    "    # Merge on Ticker to find stocks that appear in BOTH lists\n",
    "    # We use an 'inner' join, which means \"keep only if in both\"\n",
    "    Deep_Value_Intersection = pd.merge(\n",
    "        Buffett_Value_DF[['Ticker', 'P/B Ratio', 'ROE %', 'Debt/Eq %']], \n",
    "        Fortress_Burry_EV_EBITDA[['Ticker', 'Price', 'Sector', 'EV/EBITDA', 'Sector_Avg_EV_EBITDA', 'Discount_%', 'Tier']],\n",
    "        on='Ticker', \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if not Deep_Value_Intersection.empty:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üíé DEEP VALUE GEMS FOUND: {len(Deep_Value_Intersection)}\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\")\n",
    "        \n",
    "        # Sort by the \"Discount\" (how cheap they are vs sector)\n",
    "        Deep_Value_Intersection = Deep_Value_Intersection.sort_values(by='Discount_%', ascending=False)\n",
    "        \n",
    "        cols = ['Ticker', 'Price', 'Tier', 'P/B Ratio', 'EV/EBITDA', 'Sector_Avg_EV_EBITDA', 'Discount_%', 'Sector']\n",
    "        display(Deep_Value_Intersection[cols])\n",
    "        \n",
    "        # Optional: Save to CSV\n",
    "        Deep_Value_Intersection.to_csv(DEEPVAL_CSV, index=False)\n",
    "        print(f\"\\nSaved {len(Deep_Value_Intersection)} stocks to 'Deep_Value_Gems.csv'\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed BOTH filters.\")\n",
    "        print(\"This means no stock is both 'Below Book Value' AND 'Cheaper than Sector Average' at the same time.\")\n",
    "        print(f\"Buffett Count: {len(Buffett_Value_DF)} | Burry Count: {len(Fortress_Burry_EV_EBITDA)}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot combine. One of the filters returned 0 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 12 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n",
      "\n",
      "--- Final Watchlist ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Change_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "52W_MA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Drop_from_High_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target_Price",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Rel_Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5d820df5-7fb2-4803-b358-7193be020c36",
       "rows": [
        [
         "6",
         "GRND",
         "13.54",
         "0.97",
         "17.62",
         "-46.12",
         "1.40",
         "21.75",
         "0.83",
         "3.18"
        ],
        [
         "0",
         "ADMA",
         "18.24",
         "-0.65",
         "17.91",
         "-28.94",
         "1.00",
         "30.00",
         "0.76",
         "3.26"
        ],
        [
         "7",
         "MIR",
         "23.42",
         "-1.18",
         "19.97",
         "-22.65",
         "1.12",
         "30.62",
         "0.71",
         "3.49"
        ],
        [
         "11",
         "UBER",
         "81.71",
         "-0.5",
         "84.7",
         "-19.88",
         "1.47",
         "112.40",
         "0.42",
         "2.39"
        ],
        [
         "9",
         "SEI",
         "45.97",
         "-0.28",
         "32.67",
         "-19.41",
         "1.17",
         "65.45",
         "0.69",
         "5.9"
        ],
        [
         "5",
         "FLEX",
         "60.42",
         "-2.03",
         "48.48",
         "-16.34",
         "1.50",
         "76.00",
         "0.31",
         "2.91"
        ],
        [
         "2",
         "ARCC",
         "20.23",
         "-0.3",
         "20.48",
         "-9.64",
         "1.27",
         "22.64",
         "0.89",
         "1.38"
        ],
        [
         "10",
         "SVM",
         "8.34",
         "-2.8",
         "4.91",
         "-9.05",
         "1.17",
         "9.43",
         "0.57",
         "3.62"
        ],
        [
         "8",
         "ONB",
         "22.31",
         "-1.33",
         "21.41",
         "-6.56",
         "1.85",
         "25.92",
         "0.76",
         "2.14"
        ],
        [
         "1",
         "APG",
         "38.26",
         "-1.54",
         "31.52",
         "-5.72",
         "1.45",
         "43.40",
         "1.01",
         "1.93"
        ],
        [
         "4",
         "DD",
         "40.2",
         "-1.18",
         "31.97",
         "-3.94",
         "1.48",
         "47.19",
         "0.61",
         "2.23"
        ],
        [
         "3",
         "BANC",
         "19.29",
         "-0.77",
         "15.4",
         "-3.89",
         "1.27",
         "22.41",
         "0.56",
         "2.17"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change_%</th>\n",
       "      <th>52W_MA</th>\n",
       "      <th>Drop_from_High_%</th>\n",
       "      <th>Recom</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Rel_Volume</th>\n",
       "      <th>Volatility_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRND</td>\n",
       "      <td>13.54</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17.62</td>\n",
       "      <td>-46.12</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMA</td>\n",
       "      <td>18.24</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>17.91</td>\n",
       "      <td>-28.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MIR</td>\n",
       "      <td>23.42</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>19.97</td>\n",
       "      <td>-22.65</td>\n",
       "      <td>1.12</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UBER</td>\n",
       "      <td>81.71</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>84.70</td>\n",
       "      <td>-19.88</td>\n",
       "      <td>1.47</td>\n",
       "      <td>112.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEI</td>\n",
       "      <td>45.97</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>32.67</td>\n",
       "      <td>-19.41</td>\n",
       "      <td>1.17</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FLEX</td>\n",
       "      <td>60.42</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>48.48</td>\n",
       "      <td>-16.34</td>\n",
       "      <td>1.50</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARCC</td>\n",
       "      <td>20.23</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>20.48</td>\n",
       "      <td>-9.64</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.64</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8.34</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>4.91</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ONB</td>\n",
       "      <td>22.31</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>21.41</td>\n",
       "      <td>-6.56</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APG</td>\n",
       "      <td>38.26</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>31.52</td>\n",
       "      <td>-5.72</td>\n",
       "      <td>1.45</td>\n",
       "      <td>43.40</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD</td>\n",
       "      <td>40.20</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>31.97</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>1.48</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANC</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Price  Change_%  52W_MA  Drop_from_High_% Recom Target_Price  Rel_Volume  Volatility_%\n",
       "6    GRND  13.54      0.97   17.62            -46.12  1.40        21.75        0.83          3.18\n",
       "0    ADMA  18.24     -0.65   17.91            -28.94  1.00        30.00        0.76          3.26\n",
       "7     MIR  23.42     -1.18   19.97            -22.65  1.12        30.62        0.71          3.49\n",
       "11   UBER  81.71     -0.50   84.70            -19.88  1.47       112.40        0.42          2.39\n",
       "9     SEI  45.97     -0.28   32.67            -19.41  1.17        65.45        0.69          5.90\n",
       "5    FLEX  60.42     -2.03   48.48            -16.34  1.50        76.00        0.31          2.91\n",
       "2    ARCC  20.23     -0.30   20.48             -9.64  1.27        22.64        0.89          1.38\n",
       "10    SVM   8.34     -2.80    4.91             -9.05  1.17         9.43        0.57          3.62\n",
       "8     ONB  22.31     -1.33   21.41             -6.56  1.85        25.92        0.76          2.14\n",
       "1     APG  38.26     -1.54   31.52             -5.72  1.45        43.40        1.01          1.93\n",
       "4      DD  40.20     -1.18   31.97             -3.94  1.48        47.19        0.61          2.23\n",
       "3    BANC  19.29     -0.77   15.40             -3.89  1.27        22.41        0.56          2.17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND','ARCC','BANC','ONB','UBER','ADMA','MIR','APG','SEI','FLEX','DD','SVM'] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 20: \n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                \n",
    "                high_52 = df['High'].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                \n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df['Close'].pct_change().std() * 100\n",
    "                \n",
    "                # Relative Volume\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df['Close'].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100 \n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '52W_MA': round(ma_52w, 2),          # <--- Added Here\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = ['Ticker', 'Price', 'Change_%', '52W_MA', 'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if 'Drop_from_High_%' in watchlist_df.columns:\n",
    "        watchlist_df['Drop_from_High_%'] = pd.to_numeric(watchlist_df['Drop_from_High_%'], errors='coerce')\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        display(watchlist_df.sort_values(by='Drop_from_High_%', ascending=True))\n",
    "    else:\n",
    "        display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01880793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import google as genai\n",
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "import json\n",
    "import plotly.express as px\n",
    "import sys\n",
    "#!\"{sys.executable}\" -m pip install google.genai\n",
    "#!\"{sys.executable}\" -m pip install plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b06187d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_gemini = ['SVM'] \n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "333020a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded securely.\n",
      "\n",
      "üß† Gemini 3 is thinking (High Reasoning Mode)... analyzing $['SVM']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üß† Gemini 3 Sentiment Report: Silvercorp Metals Inc. (SVM)\n",
       "**Reasoning Depth:** High  \n",
       "**Sentiment Score:** 8.5/10  \n",
       "**Verdict:** Buy / Long-Term Value Play\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis (Why it goes up)\n",
       "*   **Operational Excellence & Cost Control**: SVM remains one of the lowest-cost silver producers globally. With an All-In Sustaining Cost (AISC) hovering around **$14.31‚Äì$15.50 per ounce**, the company enjoys massive margins as silver prices remain elevated in the $30+ range.\n",
       "*   **The \"Ecuador Pivot\"**: The market is re-rating SVM as it transitions from a China-centric miner to a diversified global player. The **Condor Gold Project** and the **El Domo (Adventus) acquisition** are projected to nearly double revenue by Fiscal Year 2028 (projected $614M vs. $298M in FY2025).\n",
       "*   **Strong Financial Fortress**: Unlike many junior/mid-tier miners, SVM is debt-free with a robust cash position ($52.6M in FCF for FY2025). It continues to pay a semi-annual dividend, a rarity in the sector that attracts institutional yield-seekers.\n",
       "*   **Technical Breakout**: The stock recently hit a **52-week high ($8.87)**, breaking out from a multi-year base. It is currently trading significantly above its 50-day and 200-day moving averages, signaling strong momentum.\n",
       "\n",
       "### 2. The Bear Thesis (Why it goes down)\n",
       "*   **Jurisdictional Risk (The \"China Discount\")**: Despite diversification efforts, the bulk of current cash flow still originates in China. Geopolitical tensions or regulatory shifts in Beijing remain a permanent \"black swan\" risk that keeps the P/E ratio lower than Western peers like Pan American Silver (PAAS).\n",
       "*   **Ecuador Legal Headwinds**: While the El Domo project is high-grade, mining in Ecuador has historically faced local opposition and legal challenges. Any delay in the 2027/2028 production timeline would deflate the current growth premium.\n",
       "*   **Insider \"Trim\"**: Recent small-scale insider selling (Director Yikang Liu sold ~10k shares in late Dec 2025) can be perceived by retail as a signal that the stock is nearing a local top, even if the sale represents a small fraction of his total holdings.\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "#### **News Analysis**\n",
       "Headlines over the last 30 days have been **distinctly euphoric**. The delivery of a \"Robust PEA\" (Preliminary Economic Assessment) for the Condor Gold Project in December 2025 served as a major catalyst. Media coverage shifted from \"China miner\" to \"Growth story,\" focusing on the potential for SVM to become a senior producer. There is a lack of \"fear-mongering\" news, suggesting the market has currently priced in the known geopolitical risks.\n",
       "\n",
       "#### **Smart Money**\n",
       "Institutional flow is **highly positive**. SVM is a staple in the SIL (Silver Miners) and GDXJ (Junior Gold Miners) ETFs. Fintel data shows institutional ownership has surged over 200% in the last 12-18 months. Major funds like **Millennium Management** and **Citadel** maintain positions, suggesting that \"Smart Money\" is betting on the silver macro-cycle rather than being deterred by SVM's specific geography.\n",
       "\n",
       "#### **Financial Statement Analysis**\n",
       "| Metric | FY 2023 (Actual) | FY 2024 (Actual) | FY 2025 (Actual) | FY 2026 (Est.) |\n",
       "| :--- | :--- | :--- | :--- | :--- |\n",
       "| **Revenue** | $208M | $215.2M | **$298.9M** | **$354M** |\n",
       "| **Net Income** | $21M | $36.3M | **$58.2M** | **$78M+** |\n",
       "| **Silver Prod.** | 6.6M oz | 6.2M oz | 6.9M oz | 7.6M oz |\n",
       "| **AISC** | ~$13.50 | ~$14.36 | $14.31 | ~$15.40 |\n",
       "\n",
       "*   **Analysis**: SVM has shown a 3-year CAGR in revenue of approximately 20%. The jump in FY2025 was driven by both volume and realized metal prices. For FY2026, the company is guiding for higher production (9% growth in silver), which, combined with a bullish silver price, makes the $354M revenue target conservative.\n",
       "\n",
       "#### **The \"Whisper\" Number**\n",
       "Retail sentiment on forums (Stocktwits/Reddit) is reaching a \"fever pitch.\" Traders are whispering about a **$10.00 price target** by Q2 2026. Official analyst guidance is slightly more tempered (Consensus $9.00), suggesting that while the \"smart money\" is focused on the 2028 Ecuador production, retail is chasing the immediate technical breakout.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Conclusion: Trap or Opportunity?\n",
       "The current price of **$8.45‚Äì$8.90** is **not a trap**, but rather a belated market recognition of SVM's fundamental strength. Historically, SVM has traded at a significant discount to its Net Asset Value (NAV) due to its China exposure. The \"diversification premium\" is now being applied as the Ecuador projects de-risk.\n",
       "\n",
       "**Opportunity**: SVM is currently a \"Value-Growth\" hybrid. It offers the safety of a profitable, dividend-paying cash cow with the upside of a junior developer. Any pullbacks toward the $7.80 level (former resistance) should be viewed as aggressive buying opportunities.\n",
       "\n",
       "**Final Score: 8.5/10** (Deduction only for the inherent jurisdictional volatility of mining in Ecuador and China)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# SECURE CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define the path to your key file\n",
    "# If the file is in the same folder as this notebook, just use the filename.\n",
    "KEY_FILE_PATH = \"C:\\\\Users\\\\James\\\\OneDrive - McMaster University\\\\Gemini API Key\\\\gemini_key.txt\"\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Reads the API key from a local file to avoid hardcoding it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            # .strip() removes any accidental newlines or spaces\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find the file '{filepath}'\")\n",
    "        print(\"Please create a text file with your API key in it.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Load the key and set the environment variable\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: API Key not loaded. The script will fail.\")\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_sentiment_gemini_3(tickers_gemini, company_name=None):\n",
    "    \n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"‚ùå Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† Gemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\")\n",
    "\n",
    "    # Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, \n",
    "            thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(\n",
    "            google_search=types.GoogleSearch() \n",
    "        )],\n",
    "        response_modalities=[\"TEXT\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini} ({company_name if company_name else 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology. Look for contradictions between price action and news.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric? (Look for scandals, lawsuits, or product breakthroughs).\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN in the last week?\n",
    "    3. **Institutional Flows**: Any reports of hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## üß† Gemini 3 Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance over last 3 years + expected performance)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    [Summary of whether the current price is a trap or an opportunity]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-3-flash-preview', # Or 'gemini-3-flash-preview'\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        display(Markdown(response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "# Only run this if the key loaded successfully\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
