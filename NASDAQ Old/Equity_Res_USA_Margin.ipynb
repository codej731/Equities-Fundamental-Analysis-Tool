{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "# 1. FOLDER SETUP (The Fix for GitHub Portability)\n",
    "DATA_FOLDER = \"YfinanceDataDump\"  # Relative path (creates folder in project root)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"\n",
    "\n",
    "# 2. FILE PATHS (Everything saves inside the folder now)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\")\n",
    "\n",
    "# 3. UNIVERSE FILTERS\n",
    "MIN_PRICE = 2.00               \n",
    "MIN_VOLUME = 1_000_000       \n",
    "MIN_CAP = 300_000_000        # $300M\n",
    "MIN_CURRENT_RATIO = 1.2\n",
    "MAX_PE_RATIO = 100.0         \n",
    "\n",
    "# 4. SAFETY THRESHOLDS \n",
    "MIN_INTEREST_COVERAGE = 1.5\n",
    "MIN_ROIC = 0.05              # 5%\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # 5%\n",
    "\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "CACHE_EXPIRY_DAYS = 30 \n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculates Z-Score using yfinance DataFrames.\n",
    "    Formula: 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper to safely get value from Series\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Map yfinance row names\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        if total_assets == 0 or total_liab == 0: return 0\n",
    "\n",
    "        # A: Working Capital / Total Assets\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings / Total Assets\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT / Total Assets\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Value of Equity / Total Liabilities\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Sales / Total Assets\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: FETCH COMBINED UNIVERSE (USA)\n",
    "# ==========================================\n",
    "def get_combined_universe():\n",
    "    print(\"--- STEP 1: Fetching North American Universe ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # 1. USA\n",
    "    try:\n",
    "        url_us = \"https://www.nasdaqtrader.com/dynamic/symdir/nasdaqtraded.txt\"\n",
    "        s = requests.get(url_us).content\n",
    "        df_us = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='|')\n",
    "        df_us = df_us[(df_us['Test Issue'] == 'N') & (df_us['ETF'] == 'N')]\n",
    "        us_list = [x.replace('$', '-') for x in df_us['Symbol'].astype(str) if len(x) < 5]\n",
    "        tickers.extend(us_list)\n",
    "        print(f\"   -> Found {len(us_list)} US stocks.\")\n",
    "    except:\n",
    "        print(\"   -> Error fetching USA list.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2: LIGHTWEIGHT SIEVE (YahooQuery)\n",
    "# ==========================================\n",
    "def get_initial_survivors(tickers):\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    chunk_size = 500 \n",
    "    survivors = []\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 2 == 0: print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_modules = yq.get_modules('summaryProfile summaryDetail financialData price defaultKeyStatistics')\n",
    "            \n",
    "            for symbol, data in df_modules.items():\n",
    "                if isinstance(data, str): continue \n",
    "                try:\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: price = 0\n",
    "                    \n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                         vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: cap = 0\n",
    "                    \n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)\n",
    "                    if curr_ratio is None: curr_ratio = 0\n",
    "                    if op_margins is None: op_margins = 0\n",
    "\n",
    "                    # --- P/E RATIO CHECK ---\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: continue\n",
    "\n",
    "                    # FILTERS\n",
    "                    if price < MIN_PRICE: continue\n",
    "                    if cap < MIN_CAP: continue\n",
    "                    if vol < MIN_VOLUME: continue \n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): continue\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: continue\n",
    "                    if op_margins <= 0: continue \n",
    "                    \n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)\n",
    "                    })\n",
    "                except: continue\n",
    "        except: continue\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 3: DEEP DIVE (yfinance + Cache)\n",
    "# ==========================================\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    cache = load_cache()\n",
    "    current_time = time.time()\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 20 == 0: print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        # Helper: Logic to assign Tier based on Average Margin & Safety\n",
    "        def determine_tier_history(metrics, is_fortress_margin, is_pos_margin):\n",
    "            # 1. Safety Checks (Must pass these regardless of margins)\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: return \"Risky\"\n",
    "            \n",
    "            # 2. Historical Margin Checks (Using the 4-Year Average)\n",
    "            if is_fortress_margin: \n",
    "                return \"Fortress\"  # Avg Margin > 5%\n",
    "            elif is_pos_margin:\n",
    "                return \"Strong\"    # Avg Margin > 0%\n",
    "            \n",
    "            return \"Risky\"         # Avg Margin was negative\n",
    "\n",
    "        # 1. CHECK CACHE\n",
    "        # Note: If you want to force the new logic on old cached data, you might need to clear your cache file once.\n",
    "        cached_data = cache.get(ticker)\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "            if cached_data.get('roic') == -999: continue \n",
    "            \n",
    "            # We assume cached data is valid; if you recently changed logic, \n",
    "            # the cache won't have the \"avg_margin\" flag unless we re-run. \n",
    "            # For now, we proceed with standard execution or re-fetch if needed.\n",
    "            # To be safe with new logic, we often skip cache for the first run or \n",
    "            # you can delete 'financial_cache.json' manually.\n",
    "            pass \n",
    "\n",
    "        # 2. FETCH NEW DATA\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials\n",
    "            bs = stock.balance_sheet\n",
    "            \n",
    "            if fin.empty or bs.empty:\n",
    "                cache[ticker] = {'timestamp': current_time, 'z_score': 0, 'roic': -999, 'int_cov': -999}\n",
    "                continue\n",
    "            \n",
    "            # --- A. NEW LOGIC: 4-Year Average Margin Check ---\n",
    "            try:\n",
    "                # Get Operating Income (try 'Operating Income' first, then 'EBIT')\n",
    "                if 'Operating Income' in fin.index:\n",
    "                    op_income_history = fin.loc['Operating Income']\n",
    "                elif 'EBIT' in fin.index:\n",
    "                    op_income_history = fin.loc['EBIT']\n",
    "                else:\n",
    "                    op_income_history = pd.Series([0]) \n",
    "\n",
    "                # Get Revenue\n",
    "                revenue_history = fin.loc['Total Revenue']\n",
    "                \n",
    "                # Calculate Margins for every available year\n",
    "                # This automatically handles 1, 2, 3, or 4 years of data\n",
    "                yearly_margins = (op_income_history / revenue_history).dropna()\n",
    "                \n",
    "                if len(yearly_margins) > 0:\n",
    "                    avg_margin = yearly_margins.mean()\n",
    "                    \n",
    "                    # The Uniform Rule: Is the AVERAGE above the threshold?\n",
    "                    is_fortress_margin = avg_margin > FORTRESS_MARGIN_THRESHOLD\n",
    "                    is_positive_margin = avg_margin > 0\n",
    "                else:\n",
    "                    is_fortress_margin = False\n",
    "                    is_positive_margin = False\n",
    "\n",
    "            except Exception as e:\n",
    "                # Fail safe\n",
    "                is_fortress_margin = False\n",
    "                is_positive_margin = False\n",
    "            # ---------------------------------------------------\n",
    "\n",
    "            # --- B. Standard Calculations (Safety Checks) ---\n",
    "            def get_item(df, keys):\n",
    "                for k in keys:\n",
    "                    if k in df.index: return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            # Interest Coverage\n",
    "            int_exp = abs(int_exp)\n",
    "            if int_exp == 0: int_cov = 100\n",
    "            else: int_cov = ebit / int_exp\n",
    "            \n",
    "            # ROIC\n",
    "            invested_cap = total_assets - curr_liab\n",
    "            if invested_cap <= 0: roic = 0\n",
    "            else: roic = ebit / invested_cap\n",
    "            \n",
    "            # Z-Score\n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            # Cache the metrics\n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            # --- C. Determine Final Tier ---\n",
    "            tier = determine_tier_history(metrics, is_fortress_margin, is_positive_margin)\n",
    "\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'], # We still show the current TTM margin for reference\n",
    "                'Avg Margin (4Y)': round(avg_margin * 100, 2) if 'avg_margin' in locals() else 0, # Optional: Add this if you want to see it\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    save_cache(cache)\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching North American Universe ---\n",
      "   -> Found 6013 US stocks.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 6013 stocks ---\n",
      " -> Processing Batch 1/13...\n",
      " -> Processing Batch 3/13...\n",
      " -> Processing Batch 5/13...\n",
      " -> Processing Batch 7/13...\n",
      " -> Processing Batch 9/13...\n",
      " -> Processing Batch 11/13...\n",
      " -> Processing Batch 13/13...\n",
      "No stocks passed the initial lightweight filter.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n‚úÖ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                final_results = final_results.sort_values(by=['Tier', 'Z-Score'], ascending=[True, False])\n",
    "                \n",
    "                # 1. Standard Split\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # 3. Save Files (Updated to use Relative Paths from Cell 2)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error Saving Files: {e}\")\n",
    "                    print(\"Check if the file is open in Excel or if the folder exists.\")\n",
    "                \n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the function (if you haven't already in a previous cell)\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks (From Memory) ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 10 == 0: print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Must be better than 2.0 (Lower is better)\n",
    "            if rec_mean is None or rec_mean > 2.0: continue\n",
    "            \n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Merge with existing data\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2) # Polite delay\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE IT (Run this part!)\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by best Analyst Rating (Lower is better) or Upside\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        # Display Results\n",
    "        print(\"\\n‚úÖ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(\"Saved to 'Analyst_Fortress_Picks.csv'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå 'final_results' variable not found. Please run the Main Filter first.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "# ==========================================\n",
    "# BUFFETT \"BELOW NAV\" SCAN\n",
    "# ==========================================\n",
    "def get_buffett_value_picks(df_input):\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Use YahooQuery for speed (Key Stats are summary data, no throttling risk here)\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # We need defaultKeyStatistics (P/B) and financialData (ROE, Debt)\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        # Skip if None, > 1.0, or negative (insolvent)\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: continue\n",
    "\n",
    "                        # 2. Positive ROE (No Zombies)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: continue\n",
    "\n",
    "                        # 3. Reasonable Debt (Safety)\n",
    "                        # Buffett hates high leverage on weak companies\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: continue \n",
    "\n",
    "                        # Get base data from input_df\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "\n",
    "                        # Add new Value Metrics\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: continue\n",
    "        except: continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION BLOCK\n",
    "# ==========================================\n",
    "# Ensure we have the 'final_results' from the Main Filter\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    \n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        # Sort by P/B Ratio (Cheapest first)\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        \n",
    "        # Save results\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks (Trading < Book Value)\")\n",
    "        print(\"Saved to: 'Buffett_Value_Picks.csv'\")\n",
    "        \n",
    "        # Display\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\")\n",
    "else:\n",
    "    print(\"‚ùå 'final_results' variable not found. Please run the Main Filter first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c744c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è 'fortress_df' not found or empty.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfortress_df\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found or empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m Fortress_insiders \u001b[38;5;241m=\u001b[39m filter_for_insider_buying(target_tickers)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Display so Data Wrangler picks it up\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Created \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFortress_insiders\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(Fortress_insiders)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_tickers' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "\n",
    "# Ignore these specific FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ==========================================\n",
    "# INSIDER FILTER FUNCTION (With Price)\n",
    "# ==========================================\n",
    "def filter_for_insider_buying(tickers):\n",
    "    print(f\"üïµÔ∏è Scanning {len(tickers)} stocks for Insider Buying & Price...\")\n",
    "    insider_picks = []\n",
    "    \n",
    "    # Chunk to prevent timeouts\n",
    "    chunk_size = 20\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            # Initialize Ticker object for the chunk\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            \n",
    "            # 1. Fetch Insider Transactions\n",
    "            df_insiders = yq.insider_transactions\n",
    "            \n",
    "            # 2. Fetch Price Data (New Step)\n",
    "            # This returns a dictionary: {'TICKER': {'regularMarketPrice': 10.50, ...}}\n",
    "            price_data = yq.price\n",
    "            \n",
    "            # Validation: Ensure we have data to work with\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, 'reset_index'): \n",
    "                continue\n",
    "            \n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders['symbol'].values:\n",
    "                    continue\n",
    "                \n",
    "                # --- INSIDER LOGIC ---\n",
    "                stock_tx = df_insiders[df_insiders['symbol'] == symbol].copy()\n",
    "                \n",
    "                buys = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Purchase\", case=False, na=False)]\n",
    "                sells = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Sale\", case=False, na=False)]\n",
    "                \n",
    "                buy_vol = buys['shares'].sum() if not buys.empty else 0\n",
    "                sell_vol = sells['shares'].sum() if not sells.empty else 0\n",
    "                \n",
    "                # --- PRICE LOGIC ---\n",
    "                current_price = None\n",
    "                try:\n",
    "                    # Safely attempt to grab the price from the dictionary\n",
    "                    if isinstance(price_data, dict) and symbol in price_data:\n",
    "                        current_price = price_data[symbol].get('regularMarketPrice', None)\n",
    "                except Exception:\n",
    "                    current_price = None\n",
    "\n",
    "                # Only keep if Net Buying is Positive\n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Current_Price': current_price, # <--- New Column\n",
    "                        'Insider_Buys_Count': len(buys),\n",
    "                        'Net_Shares_Bought': buy_vol - sell_vol\n",
    "                    })\n",
    "                        \n",
    "        except Exception as e:\n",
    "            # print(f\"Error on chunk: {e}\") # Uncomment for debugging\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE 'Fortress_insiders' DATAFRAME\n",
    "# ==========================================\n",
    "\n",
    "# Use fortress_df if it exists, otherwise use the top 20 backup list\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'fortress_df' not found or empty.\")\n",
    "\n",
    "# Run the filter\n",
    "Fortress_insiders = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# Display so Data Wrangler picks it up\n",
    "print(f\"‚úÖ Created 'Fortress_insiders' with {len(Fortress_insiders)} rows.\")\n",
    "display(Fortress_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 171 stocks for Insider Buying & Price...\n",
      "No stocks passed all filters.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "        \n",
    "    tickers = df_insiders['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders # Return original if no data found\n",
    "            \n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list just in case\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(insider_winners, max_score=2.5)\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\")\n",
    "    display(Fortress_insiders_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 12 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n",
      "\n",
      "--- Final Watchlist ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Change_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "52W_MA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Drop_from_High_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target_Price",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Rel_Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7aa2c316-1bc3-48e8-afad-0c6692ccbbc7",
       "rows": [
        [
         "6",
         "GRND",
         "13.54",
         "0.97",
         "17.62",
         "-46.12",
         "1.40",
         "21.75",
         "0.83",
         "3.18"
        ],
        [
         "0",
         "ADMA",
         "18.24",
         "-0.65",
         "17.91",
         "-28.94",
         "1.00",
         "30.00",
         "0.76",
         "3.26"
        ],
        [
         "7",
         "MIR",
         "23.42",
         "-1.18",
         "19.97",
         "-22.65",
         "1.12",
         "30.62",
         "0.71",
         "3.49"
        ],
        [
         "11",
         "UBER",
         "81.71",
         "-0.5",
         "84.7",
         "-19.88",
         "1.47",
         "112.40",
         "0.42",
         "2.39"
        ],
        [
         "9",
         "SEI",
         "45.97",
         "-0.28",
         "32.67",
         "-19.41",
         "1.17",
         "65.45",
         "0.69",
         "5.9"
        ],
        [
         "5",
         "FLEX",
         "60.42",
         "-2.03",
         "48.48",
         "-16.34",
         "1.50",
         "76.00",
         "0.31",
         "2.91"
        ],
        [
         "2",
         "ARCC",
         "20.23",
         "-0.3",
         "20.48",
         "-9.64",
         "1.27",
         "22.64",
         "0.89",
         "1.38"
        ],
        [
         "10",
         "SVM",
         "8.34",
         "-2.8",
         "4.91",
         "-9.05",
         "1.17",
         "9.43",
         "0.57",
         "3.62"
        ],
        [
         "8",
         "ONB",
         "22.31",
         "-1.33",
         "21.41",
         "-6.56",
         "1.85",
         "25.92",
         "0.76",
         "2.14"
        ],
        [
         "1",
         "APG",
         "38.26",
         "-1.54",
         "31.52",
         "-5.72",
         "1.45",
         "43.40",
         "1.01",
         "1.93"
        ],
        [
         "4",
         "DD",
         "40.2",
         "-1.18",
         "31.97",
         "-3.94",
         "1.48",
         "47.19",
         "0.61",
         "2.23"
        ],
        [
         "3",
         "BANC",
         "19.29",
         "-0.77",
         "15.4",
         "-3.89",
         "1.27",
         "22.41",
         "0.56",
         "2.17"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change_%</th>\n",
       "      <th>52W_MA</th>\n",
       "      <th>Drop_from_High_%</th>\n",
       "      <th>Recom</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Rel_Volume</th>\n",
       "      <th>Volatility_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRND</td>\n",
       "      <td>13.54</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17.62</td>\n",
       "      <td>-46.12</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMA</td>\n",
       "      <td>18.24</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>17.91</td>\n",
       "      <td>-28.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MIR</td>\n",
       "      <td>23.42</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>19.97</td>\n",
       "      <td>-22.65</td>\n",
       "      <td>1.12</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UBER</td>\n",
       "      <td>81.71</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>84.70</td>\n",
       "      <td>-19.88</td>\n",
       "      <td>1.47</td>\n",
       "      <td>112.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEI</td>\n",
       "      <td>45.97</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>32.67</td>\n",
       "      <td>-19.41</td>\n",
       "      <td>1.17</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FLEX</td>\n",
       "      <td>60.42</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>48.48</td>\n",
       "      <td>-16.34</td>\n",
       "      <td>1.50</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARCC</td>\n",
       "      <td>20.23</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>20.48</td>\n",
       "      <td>-9.64</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.64</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8.34</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>4.91</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ONB</td>\n",
       "      <td>22.31</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>21.41</td>\n",
       "      <td>-6.56</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APG</td>\n",
       "      <td>38.26</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>31.52</td>\n",
       "      <td>-5.72</td>\n",
       "      <td>1.45</td>\n",
       "      <td>43.40</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD</td>\n",
       "      <td>40.20</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>31.97</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>1.48</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANC</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Price  Change_%  52W_MA  Drop_from_High_% Recom Target_Price  Rel_Volume  Volatility_%\n",
       "6    GRND  13.54      0.97   17.62            -46.12  1.40        21.75        0.83          3.18\n",
       "0    ADMA  18.24     -0.65   17.91            -28.94  1.00        30.00        0.76          3.26\n",
       "7     MIR  23.42     -1.18   19.97            -22.65  1.12        30.62        0.71          3.49\n",
       "11   UBER  81.71     -0.50   84.70            -19.88  1.47       112.40        0.42          2.39\n",
       "9     SEI  45.97     -0.28   32.67            -19.41  1.17        65.45        0.69          5.90\n",
       "5    FLEX  60.42     -2.03   48.48            -16.34  1.50        76.00        0.31          2.91\n",
       "2    ARCC  20.23     -0.30   20.48             -9.64  1.27        22.64        0.89          1.38\n",
       "10    SVM   8.34     -2.80    4.91             -9.05  1.17         9.43        0.57          3.62\n",
       "8     ONB  22.31     -1.33   21.41             -6.56  1.85        25.92        0.76          2.14\n",
       "1     APG  38.26     -1.54   31.52             -5.72  1.45        43.40        1.01          1.93\n",
       "4      DD  40.20     -1.18   31.97             -3.94  1.48        47.19        0.61          2.23\n",
       "3    BANC  19.29     -0.77   15.40             -3.89  1.27        22.41        0.56          2.17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND','ARCC','BANC','ONB','UBER','ADMA','MIR','APG','SEI','FLEX','DD','SVM'] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 20: \n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                \n",
    "                high_52 = df['High'].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                \n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df['Close'].pct_change().std() * 100\n",
    "                \n",
    "                # Relative Volume\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df['Close'].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100 \n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '52W_MA': round(ma_52w, 2),          # <--- Added Here\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = ['Ticker', 'Price', 'Change_%', '52W_MA', 'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if 'Drop_from_High_%' in watchlist_df.columns:\n",
    "        watchlist_df['Drop_from_High_%'] = pd.to_numeric(watchlist_df['Drop_from_High_%'], errors='coerce')\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        display(watchlist_df.sort_values(by='Drop_from_High_%', ascending=True))\n",
    "    else:\n",
    "        display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01880793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import google as genai\n",
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "import json\n",
    "import plotly.express as px\n",
    "import sys\n",
    "#!\"{sys.executable}\" -m pip install google.genai\n",
    "#!\"{sys.executable}\" -m pip install plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06187d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_gemini = ['SVM'] \n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333020a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded securely.\n",
      "\n",
      "üß† Gemini 3 is thinking (High Reasoning Mode)... analyzing $['SVM']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üß† Gemini 3 Sentiment Report: Silvercorp Metals Inc. (SVM)\n",
       "**Reasoning Depth:** High\n",
       "**Sentiment Score:** 8.5/10\n",
       "**Verdict:** **Strong Buy / Bullish Momentum**\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis (Why it goes up)\n",
       "*   **Macro Silver Tailwinds**: Silver prices hit record highs in late 2025, providing a massive expansion in profit margins for high-grade producers like SVM.\n",
       "*   **Asset Diversification (The \"Ecuador Factor\")**: The recent **Condor Gold Project PEA (Preliminary Economic Assessment)** released on December 22, 2025, has been labeled \"robust\" by analysts. This significantly reduces the company's \"China-only\" discount.\n",
       "*   **Record Cash Position**: With over **$355M in cash and no debt**, SVM is a fortress in a sector typically plagued by high leverage. This allows for both organic growth and potential M&A without shareholder dilution.\n",
       "*   **Operational Excellence**: SVM continues to report record revenues ($84M+ in recent quarters) and record silver production (1.9M oz/quarter) due to mill expansions at the Ying Mining District.\n",
       "\n",
       "### 2. The Bear Thesis (Why it goes down)\n",
       "*   **The \"China Discount\"**: Despite diversification, the core of SVM‚Äôs cash flow still originates in China, keeping it susceptible to geopolitical tensions and ESG-driven capital flight.\n",
       "*   **Insider Selling Near Highs**: Director Yikang Liu sold approximately 10,000 shares on December 31, 2025. While a small amount, sales at 52-week highs can signal to retail investors that the local ceiling has been reached.\n",
       "*   **Execution Risk in Ecuador**: Developing the Condor and Curipamba projects in Ecuador involves significant regulatory and environmental hurdles that could delay production targets (H2 2026).\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "#### **News Analysis: \"Euphoria with a Dash of Pragmatism\"**\n",
       "The news cycle over the last 30 days has been dominated by SVM hitting **52-week highs (recently touching $8.90)**. Headlines are leaning toward **euphoria**, driven by the \"Silver Explosion\" of 2025. Unlike other miners that rely on future exploration, SVM‚Äôs news is grounded in *actual production beats* and *completed mill expansions*. The December 22, 2025, Condor PEA served as a major catalyst, shifting the narrative from a \"stagnant China play\" to a \"diversified growth story.\"\n",
       "\n",
       "#### **Smart Money: Institutional Accumulation**\n",
       "Institutional flow is strongly positive. The **Amplify Junior Silver Miners ETF (SILJ)** filed a Schedule 13G in late November 2025, disclosing a **5.01% passive stake** (over 10.9M shares). This institutional \"floor\" suggests that big money is rotating into SVM as a high-liquidity vehicle to play the silver rally. While retail ownership remains high (~55%), the entry of major ETFs indicates a shift toward institutional stability.\n",
       "\n",
       "#### **Financial Statement Analysis**\n",
       "*   **Historic Performance (3-Year Trend)**: SVM has seen a meteoric rise in profitability. Revenue jumped from ~$215M (2023) to ~$299M (2024), with 2025 estimates tracking significantly higher due to silver prices.\n",
       "*   **Margins**: The company maintains an **operating margin of +42.7%**, which is top-tier for the industry.\n",
       "*   **Expected Performance (2026)**: Analysts are projecting an **EPS of $0.15** for the next quarterly report (Feb 10, 2026), a significant jump from the $0.09‚Äì$0.10 range seen in early 2025.\n",
       "\n",
       "#### **The \"Whisper\" Number**\n",
       "Retail sentiment on forums (Stocktwits/Reddit) is intensely bullish. The \"whisper\" expectation for the February earnings is slightly higher than official guidance, with traders betting on an EPS surprise of **$0.17-$0.18** due to the higher silver-realized prices in Q4 2025.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Conclusion\n",
       "**Opportunity or Trap?**\n",
       "Silvercorp Metals is currently an **Opportunity**. \n",
       "\n",
       "While the stock is trading near its 52-week high, the reasoning engine suggests this is not a \"blow-off top\" but a **fundamental re-rating**. The combination of record silver prices, a massive cash pile, and the successful de-risking of the Ecuador project justifies a higher P/E multiple than its historic average. \n",
       "\n",
       "**Analyst Note**: Watch the $9.00 resistance level. A clean break above $9.00 on high volume‚Äîsupported by a beat in the Feb 2026 earnings‚Äîcould open the door to a **$12.00-$13.00 price target** as suggested by BMO and Canaccord‚Äôs recent upgrades. Any pullback toward the $7.80-$8.10 support range should be viewed as a high-conviction entry point for long-term holders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# SECURE CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define the path to your key file\n",
    "# If the file is in the same folder as this notebook, just use the filename.\n",
    "KEY_FILE_PATH = \"C:\\\\Users\\\\James\\\\OneDrive - McMaster University\\\\Gemini API Key\\\\gemini_key.txt\"\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Reads the API key from a local file to avoid hardcoding it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            # .strip() removes any accidental newlines or spaces\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find the file '{filepath}'\")\n",
    "        print(\"Please create a text file with your API key in it.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Load the key and set the environment variable\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: API Key not loaded. The script will fail.\")\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_sentiment_gemini_3(tickers_gemini, company_name=None):\n",
    "    \n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"‚ùå Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† Gemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\")\n",
    "\n",
    "    # Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, \n",
    "            thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(\n",
    "            google_search=types.GoogleSearch() \n",
    "        )],\n",
    "        response_modalities=[\"TEXT\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini} ({company_name if company_name else 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology. Look for contradictions between price action and news.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric? (Look for scandals, lawsuits, or product breakthroughs).\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN in the last week?\n",
    "    3. **Institutional Flows**: Any reports of hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## üß† Gemini 3 Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance over last 3 years + expected performance)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    [Summary of whether the current price is a trap or an opportunity]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-3-flash-preview', # Or 'gemini-3-flash-preview'\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        display(Markdown(response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "# Only run this if the key loaded successfully\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
