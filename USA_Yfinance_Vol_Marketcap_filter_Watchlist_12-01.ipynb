{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6870e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching candidates for: USA...\n",
      "[Info] loading page [###---------------------------] 1/11 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_df[final_cols].head(limit_per_country * \u001b[38;5;28mlen\u001b[39m(countries))\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- Usage ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m top_picks = \u001b[43mget_filtered_picks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mUSA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m top_picks.empty:\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Ensure Price is numeric (Crucial for sorting in Data Viewer)\u001b[39;00m\n\u001b[32m     67\u001b[39m     top_picks[\u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(top_picks[\u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_filtered_picks\u001b[39m\u001b[34m(countries, limit_per_country)\u001b[39m\n\u001b[32m     20\u001b[39m foverview.set_filter(filters_dict=filters_dict)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Get results\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m df_results = \u001b[43mfoverview\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscreener_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_results.empty:\n\u001b[32m     26\u001b[39m     df_results[\u001b[33m'\u001b[39m\u001b[33mSource_Country\u001b[39m\u001b[33m'\u001b[39m] = country\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\finvizfinance\\screener\\base.py:217\u001b[39m, in \u001b[36mBase.screener_view\u001b[39m\u001b[34m(self, order, limit, select_page, verbose, ascend, columns, sleep_sec)\u001b[39m\n\u001b[32m    215\u001b[39m     progress_bar(i, page)\n\u001b[32m    216\u001b[39m \u001b[38;5;28mself\u001b[39m.request_params[\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m] = i * \u001b[38;5;28mself\u001b[39m.size + \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m soup = \u001b[43mweb_scrap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m df = \u001b[38;5;28mself\u001b[39m._parse_table(df, soup, limit)\n\u001b[32m    219\u001b[39m limit -= \u001b[38;5;28mself\u001b[39m.size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\finvizfinance\\util.py:44\u001b[39m, in \u001b[36mweb_scrap\u001b[39m\u001b[34m(url, params)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Scrap website.\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33;03m    soup(beautiful soup): website html\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     website = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxy_dict\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     website.raise_for_status()\n\u001b[32m     48\u001b[39m     soup = BeautifulSoup(website.text, \u001b[33m\"\u001b[39m\u001b[33mlxml\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:1252\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1251\u001b[39m chunk = \u001b[38;5;28mself\u001b[39m._handle_chunk(amt)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m decoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n\u001b[32m   1256\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m decoded\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:510\u001b[39m, in \u001b[36mBaseHTTPResponse._decode\u001b[39m\u001b[34m(self, data, decode_content, flush_decoder)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder:\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28mself\u001b[39m._has_decoded_content = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m.DECODER_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jdcc3\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:111\u001b[39m, in \u001b[36mGzipDecoder.decompress\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         ret += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m zlib.error:\n\u001b[32m    113\u001b[39m         previous_state = \u001b[38;5;28mself\u001b[39m._state\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from finvizfinance.screener.overview import Overview\n",
    "\n",
    "def get_filtered_picks(countries=['USA'], limit_per_country=5000):\n",
    "    all_stocks = []\n",
    "    \n",
    "    for country in countries:\n",
    "        print(f\"Fetching candidates for: {country}...\")\n",
    "        \n",
    "        try:\n",
    "            foverview = Overview()\n",
    "            \n",
    "            # --- STEP 1: Broaden the initial search ---\n",
    "            filters_dict = {\n",
    "                'Analyst Recom.': 'Strong Buy (1)',\n",
    "                'Country': country,\n",
    "                'Average Volume': 'Over 2M', # Added volume filter for liquidity\n",
    "                'Market Cap.': '+Small (over $300mln)'\n",
    "            }\n",
    "            foverview.set_filter(filters_dict=filters_dict)\n",
    "            \n",
    "            # Get results\n",
    "            df_results = foverview.screener_view()\n",
    "            \n",
    "            if not df_results.empty:\n",
    "                df_results['Source_Country'] = country\n",
    "                all_stocks.append(df_results)\n",
    "            else:\n",
    "                print(f\"   No stocks found for {country}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Error fetching {country}: {e}\")\n",
    "\n",
    "    if not all_stocks:\n",
    "        print(\"\\nNo stocks found from any country.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Combine all results\n",
    "    combined_df = pd.concat(all_stocks, ignore_index=True)\n",
    "    \n",
    "    # --- STEP 2: The \"Option 2\" Pandas Filter ---\n",
    "    cols = combined_df.columns.tolist()\n",
    "    recom_col = 'Recom' if 'Recom' in cols else 'Analyst Recom'\n",
    "    \n",
    "    if recom_col in cols:\n",
    "        # Convert column to numbers\n",
    "        combined_df[recom_col] = pd.to_numeric(combined_df[recom_col], errors='coerce')\n",
    "        \n",
    "        # Filter: keep anything <= 1.5 (Strong Buys)\n",
    "        print(f\"Filtering out 'Hold' or worse (Rating > 1.5)...\")\n",
    "        combined_df = combined_df[combined_df[recom_col] <= 1.0]\n",
    "        \n",
    "        # Sort by best rating\n",
    "        combined_df = combined_df.sort_values(by=recom_col, ascending=True)\n",
    "\n",
    "    # Clean up columns\n",
    "    desired_cols = ['Ticker', 'Company', 'Sector', 'Price', 'Source_Country', recom_col]\n",
    "    final_cols = [c for c in desired_cols if c in combined_df.columns]\n",
    "    \n",
    "    return combined_df[final_cols].head(limit_per_country * len(countries))\n",
    "\n",
    "# --- Usage ---\n",
    "top_picks = get_filtered_picks(['USA'])\n",
    "\n",
    "if not top_picks.empty:\n",
    "    # Ensure Price is numeric (Crucial for sorting in Data Viewer)\n",
    "    top_picks['Price'] = pd.to_numeric(top_picks['Price'], errors='coerce')\n",
    "\n",
    "    print(f\"\\nSuccess! Found {len(top_picks)} candidates.\")\n",
    "    print(\"Variable 'top_picks' is ready for the Data Viewer.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 109 stocks between $5 and $30.\n"
     ]
    }
   ],
   "source": [
    "if not top_picks.empty:\n",
    "    # Ensure the 'Price' column is numeric\n",
    "    top_picks['Price'] = pd.to_numeric(top_picks['Price'], errors='coerce')\n",
    "\n",
    "    # CORRECT WAY: Use '&' with parentheses\n",
    "    mid_picks = top_picks[(top_picks['Price'] > 5) & (top_picks['Price'] < 30)]\n",
    "\n",
    "    print(f\"\\nFound {len(mid_picks)} stocks between $5 and $30.\")\n",
    "    # print(cheap_picks) # Uncomment if you want to see the list in output\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 28 stocks less than $5\n"
     ]
    }
   ],
   "source": [
    "# filter for price range less than $5 a bit gambly\n",
    "if not top_picks.empty:\n",
    "    # Ensure the 'Price' column is numeric\n",
    "    top_picks['Price'] = pd.to_numeric(top_picks['Price'], errors='coerce')\n",
    "\n",
    "    # CORRECT WAY: Use '&' with parentheses\n",
    "    cheap_picks = top_picks[(top_picks['Price'] < 5)]\n",
    "\n",
    "    print(f\"\\nFound {len(cheap_picks)} stocks less than $5\")\n",
    "    # print(cheap_picks) # Uncomment if you want to see the list in output\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d93732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 98 stocks greater than $20.\n"
     ]
    }
   ],
   "source": [
    "# filter for price range less than $5 a bit gambly\n",
    "if not top_picks.empty:\n",
    "    # Ensure the 'Price' column is numeric\n",
    "    top_picks['Price'] = pd.to_numeric(top_picks['Price'], errors='coerce')\n",
    "\n",
    "    # CORRECT WAY: Use '&' with parentheses\n",
    "    Main_TFSA_picks = top_picks[(top_picks['Price'] > 20)]\n",
    "\n",
    "    print(f\"\\nFound {len(Main_TFSA_picks)} stocks greater than $20.\")\n",
    "    # print(cheap_picks) # Uncomment if you want to see the list in output\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc7adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport yfinance as yf\\nimport time\\n\\n# Loop through EVERY symbol in the list (removed the [:3])\\nfor symbol in ticker_list:\\n\\n    # 1. Fetch data\\n    stock = yf.Ticker(symbol)\\n    print(f\"\\n--- Checking {symbol} ---\")\\n\\n    try:\\n        # 2. Get the upgrades/downgrades\\n        upgrades = stock.upgrades_downgrades\\n\\n        if not upgrades.empty:\\n            # Filter for 2025 actions using the .index fix\\n            recent = upgrades[upgrades.index >= \\'2025-11-01\\']\\n\\n            if not recent.empty:\\n                print(recent)\\n            else:\\n                print(f\"No actions for {symbol} in 2025.\")\\n        else:\\n            print(f\"No analyst history found for {symbol}.\")\\n\\n    except Exception as e:\\n        print(f\"Error fetching {symbol}: {e}\")\\n\\n    # 3. CRITICAL: Sleep for 1 second to avoid getting banned\\n    time.sleep(1)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import yfinance as yf\n",
    "import time\n",
    "\n",
    "# Loop through EVERY symbol in the list (removed the [:3])\n",
    "for symbol in ticker_list:\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    stock = yf.Ticker(symbol)\n",
    "    print(f\"\\n--- Checking {symbol} ---\")\n",
    "    \n",
    "    try:\n",
    "        # 2. Get the upgrades/downgrades\n",
    "        upgrades = stock.upgrades_downgrades\n",
    "        \n",
    "        if not upgrades.empty:\n",
    "            # Filter for 2025 actions using the .index fix\n",
    "            recent = upgrades[upgrades.index >= '2025-11-01']\n",
    "            \n",
    "            if not recent.empty:\n",
    "                print(recent)\n",
    "            else:\n",
    "                print(f\"No actions for {symbol} in 2025.\")\n",
    "        else:\n",
    "            print(f\"No analyst history found for {symbol}.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {symbol}: {e}\")\n",
    "\n",
    "    # 3. CRITICAL: Sleep for 1 second to avoid getting banned\n",
    "    time.sleep(1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2cf266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 4 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdcc3\\AppData\\Local\\Temp\\ipykernel_15012\\3864211186.py:42: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, period=\"2y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Watchlist ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Change_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1M_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3M_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6M_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "YTD_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Drop_from_High_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Target_Price",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Rel_Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3df00d85-ef5b-4ac7-9d7c-a820b979fc91",
       "rows": [
        [
         "0",
         "BTO.TO",
         "6.41",
         "-1.23",
         "4.4",
         "9.91",
         "31.9",
         "85.35",
         "-23.23",
         null,
         null,
         "0.68",
         "3.95"
        ],
        [
         "1",
         "GRND",
         "12.85",
         "0.16",
         "-7.29",
         "-15.96",
         "-48.04",
         "-27.97",
         "-48.87",
         "1.40",
         "21.75",
         "0.55",
         "5.29"
        ],
        [
         "2",
         "STUB",
         "11.08",
         "-5.54",
         "-42.14",
         null,
         null,
         null,
         "-60.27",
         "1.50",
         "24.18",
         "0.5",
         "6.75"
        ],
        [
         "3",
         "TMC",
         "6.28",
         "-9.7",
         "-11.1",
         "15.53",
         "57.91",
         "461.16",
         "-44.63",
         "1.00",
         "8.00",
         "1.46",
         "6.16"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change_%</th>\n",
       "      <th>1M_%</th>\n",
       "      <th>3M_%</th>\n",
       "      <th>6M_%</th>\n",
       "      <th>YTD_%</th>\n",
       "      <th>Drop_from_High_%</th>\n",
       "      <th>Recom</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Rel_Volume</th>\n",
       "      <th>Volatility_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTO.TO</td>\n",
       "      <td>6.41</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>4.40</td>\n",
       "      <td>9.91</td>\n",
       "      <td>31.90</td>\n",
       "      <td>85.35</td>\n",
       "      <td>-23.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRND</td>\n",
       "      <td>12.85</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-7.29</td>\n",
       "      <td>-15.96</td>\n",
       "      <td>-48.04</td>\n",
       "      <td>-27.97</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUB</td>\n",
       "      <td>11.08</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>-42.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.27</td>\n",
       "      <td>1.50</td>\n",
       "      <td>24.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMC</td>\n",
       "      <td>6.28</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>-11.10</td>\n",
       "      <td>15.53</td>\n",
       "      <td>57.91</td>\n",
       "      <td>461.16</td>\n",
       "      <td>-44.63</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>6.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Price  Change_%   1M_%   3M_%   6M_%   YTD_%  Drop_from_High_%  \\\n",
       "0  BTO.TO   6.41     -1.23   4.40   9.91  31.90   85.35            -23.23   \n",
       "1    GRND  12.85      0.16  -7.29 -15.96 -48.04  -27.97            -48.87   \n",
       "2    STUB  11.08     -5.54 -42.14    NaN    NaN     NaN            -60.27   \n",
       "3     TMC   6.28     -9.70 -11.10  15.53  57.91  461.16            -44.63   \n",
       "\n",
       "  Recom Target_Price  Rel_Volume  Volatility_%  \n",
       "0   NaN          NaN        0.68          3.95  \n",
       "1  1.40        21.75        0.55          5.29  \n",
       "2  1.50        24.18        0.50          6.75  \n",
       "3  1.00         8.00        1.46          6.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta # You might need to pip install python-dateutil\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND', 'BTO.TO', 'STUB','TMC'] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception:\n",
    "            # Silent fail for Finviz to keep output clean\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download 2 years to ensure we have enough buffer for YTD and 6M lookups\n",
    "        data = yf.download(ticker_list, period=\"2y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 2: \n",
    "                    continue\n",
    "\n",
    "                # Ensure index is Datetime\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                # Get the very latest available price\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                current_date = df.index[-1]\n",
    "                \n",
    "                # Basic Stats\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                high_52 = df['High'].tail(252).max() # approx 1 year\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day)\n",
    "                volatility = df['Close'].pct_change().tail(30).std() * 100\n",
    "                \n",
    "                # Rel Vol\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- ACCURATE DATE-BASED RETURNS ---\n",
    "                \n",
    "                def get_pct_change_by_date(target_date):\n",
    "                    # Find the index closest to the target date (method='nearest')\n",
    "                    # We limit the search to ensure we don't grab a date from 3 years ago if data is missing\n",
    "                    try:\n",
    "                        # Get indexer returns an array of integer locations\n",
    "                        loc = df.index.get_indexer([target_date], method='nearest')[0]\n",
    "                        \n",
    "                        # Check if the found date is reasonably close (within 5 days) \n",
    "                        # otherwise data is missing for that period\n",
    "                        found_date = df.index[loc]\n",
    "                        if abs((found_date - target_date).days) > 7:\n",
    "                            return np.nan\n",
    "                        \n",
    "                        old_price = df['Close'].iloc[loc]\n",
    "                        return ((current_price - old_price) / old_price) * 100\n",
    "                    except:\n",
    "                        return np.nan\n",
    "\n",
    "                # Calculate Target Dates\n",
    "                d_1m = current_date - relativedelta(months=1)\n",
    "                d_3m = current_date - relativedelta(months=3)\n",
    "                d_6m = current_date - relativedelta(months=6)\n",
    "                \n",
    "                # YTD: Calculate from the last trading day of the PREVIOUS year\n",
    "                last_year = current_date.year - 1\n",
    "                d_ytd = datetime(last_year, 12, 31)\n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '1M_%': round(get_pct_change_by_date(d_1m), 2),\n",
    "                    '3M_%': round(get_pct_change_by_date(d_3m), 2),\n",
    "                    '6M_%': round(get_pct_change_by_date(d_6m), 2),\n",
    "                    'YTD_%': round(get_pct_change_by_date(d_ytd), 2),\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error stats {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        cols = ['Ticker', 'Price', 'Change_%', '1M_%', '3M_%', '6M_%', 'YTD_%', \n",
    "                'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    print(\"\\n--- Final Watchlist ---\")\n",
    "    display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
